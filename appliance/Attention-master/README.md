# Attention-based Neural Machine Translation

This is an implementation of the attention mechanism used in "Effective
Approaches to Attention-based Neural Machine Translation" by Minh-Thang Luong,
Hieu Pham and Chistopher D. Manning. The paper can be found
[here](https://arxiv.org/abs/1508.04025).

The datasets can be downloaded from
[here](http://nlp.stanford.edu/projects/nmt/). In order to run the models as is
you will need to rename the dataset filenames according to the names found in
`main.py`. You will also need to add the "&lt;pad&gt;" token to the vocab file.
